# TIL Template

## 날짜: 2025-02-18

### 스크럼
- 학습 목표 1 : 머신러닝 강의
- 학습 목표 2 : 미니퀘스트 한개 풀기
- 학습 목표 3

### 새로 배운 내용
#### 주제 1: 머신러닝 강의
### PyTorch
- 직관적인 코딩 스타일과 동적 계산 그래프를 통해 딥러닝 모델을 구축과 디버깅을 용이하게 하고, 현재 연구와 실무에서 주로 사용되는 강력한 프레임워크이다.

#### 정의
- 딥러닝 모델을 쉽게 구축하고 학습할 수 있도록 설계된 파이썬 기반의 오픈소스 딥러닝 라이브러리이다.
- Autograd 모듈을 통해 연산 그래프를 자동으로 구성하고, 이를 기반으로 역전파를 수행하고 기울기를 손쉽게 계산할 수 있다.


*파이썬 클래스 문법을 더 알아보기

### Tensorflow vs PyTorch
차이점 알기.

### Kaggle
데이터를 얻기 위해 사용하는 사이트

## 데이터 전처리(2교시)
정의 : 데이터를 분석 및 모델 학습을 위해 원본 데이터를 정제하고 변화하는 과정이다.
#### 데이터 전처리 과정
- 결측값 처리(Missing Value) : 누락된 데이터를 식별하고 적절한 값으로 대체
	1. 데이터 수집 과정의 오류
	2. 응답자의 누락
	3. 데이터 통합 문제
	4. 시간적 이유 (특정시간대 누락)
- 이상치 제거 : 데이터 내 비정상적인 값들을 식별하고 제거
	1. 데이터 입력 오류
	2. 계측기기 오류
	3. 특정 이벤트나 상황
- 데이터 정규화 : 데이터를 일정한 범위( 예 : 0과 1 사이)로 변환하여 모델 학습을 돕는 과정
	1. 데이터 일관성 (데이터 비교를 위해)
	2. 알고리즘 성능
- 데이터 변환 : 데이터를 로그 변환, 원-핫 인코딩 등으로 변환
	1. 정규 분포화
	2. 분산 축소
	3. 비선형 관계

##### 원-핫 인코딩
- 범주형 데이터를 이진 벡터(이진법으로만 이루어진 벡터)로 변환되는 기법
- 왜 하는지까지 설명
##### 스케일링
- 다양한 수치 데이터가 있을 때 이를 비교, 분석하기 쉽도록 동일한 범위 또는 척도를 표현하는 방법

### 데이터 증강


### 데이터셋 분할
- 모델을 학습할 때 과적합을 방지하고, 모델의 성능을 객관적으로 평가하며, 실제 데이터를 처리할 때 모델이 잘 일반화되는지 확인하기 위해
1. 과적합 방지
	1. 모델이 학습 데이터에만 치우치지 않고, 새로운 데이터에도 잘 일반화되도록 합니다.
2. 성능 평가
	1. 모델의 성능을 객관적으로 평가할 수 있도록 합니다.
3. 일반화 확인
	1. 모델이 실제 데이터를 처리할 때 잘 일반화되는지 확인할 수 있습니다.
4. 하이퍼파라미터 튜닝
	1. 검증 데이터셋을 이용해 모델의 하이퍼파라미터를 최적화할 수 있습니다.
5. 비교 연구
	1. 다양한 모델 및 설정을 비교할 때 공정하게 성능을 평가할 수 있습니다.

### 딥러닝
- 대량의 데이터를 기반으로 비선형 모델을 자동으로 만들어주는 기법
###### 비선형이 뭔가요?
- 비선형은 입력과 출력 사이의 관계가 직선으로 표현되지 않는 특성을 의미한다.

주요 하이퍼파라미터
- 학습률 : 모델이 가중치를 업데이트하는 속도를 결정하는 값
	- 학습률이 너무 높으면 최적값을 지나치게 변동하며 수렴하지 않을 수 있고, 너무 낮으면 최적값에 도달하는 데 시간이 오래걸리거나 국소 최적점(Local Optimum)에 갇힐 가능성이 있습니다.
- 배치크기 : 한 번의 학습 단계에서 사용되는 훈련 데이터 샘플의 수
	- 배치 크기가 크면 메모리 사용량이 증가하지만 학습이 안정적이다.
- 에폭 : 전체 훈련 데이터셋을 한번 학습하는 주기의 수
- 신경망의 층 수 및 뉴런 수 : 신경망의 구조를 결정하는 하이퍼파라미터
- 드롭아웃 비율 : 학습 중 일부 뉴런을 무작위로 제외시키는 비율

### 퍼셉트론
- 퍼셉트론은 ANN(Artificial Neural Network)의 기본 단위로, 입력값을 weight(가중치)와 함께 처리하여 단일 출력을 생성하는 선형 이진 분류기이다.
- 함수 내부에 조건문이 있는 함수로 표현됨


### 오늘의 도전 과제와 해결 방법
- 도전 과제 1: 보기를 주어주고 미니퀘스트를 진행하니 수월하게 풀었습니다.

### 오늘의 회고
- 오늘도 강의장에 나와 강의를 들었습니다. 내일도 보충내용 채워서 같이 듣는것이 좋을 것 같습니다. 혁펜하임 강의로 참고하면 좋을 것 같습니다.
### 참고 자료 및 링크
- [링크 제목](URL)
- [링크 제목](URL)
