# TIL Template

## 날짜: 2025-02-21

### 스크럼
- 학습 목표 1 : 아침 스크럼에 작성한 내용 붙여넣기
- 학습 목표 2
- 학습 목표 3

### 새로 배운 내용
#### 주제 1: 딥다이브 : 데이터셋의 학습, 검증, 테스트 분할이 모델의 신뢰성 확보에 중요한 이유를 설명하시오.
1. 일반화 성능(Generalization Performance)의 중요성
    1. 모델이 훈련 데이터뿐만 아니라 새로운 데이터에서도 잘 동작하는지 평가하는 것이 중요함.
    2. 특정 데이터에만 잘 맞고 실제 환경에서 성능이 낮다면, 모델을 신뢰할 수 없음.
        1. 예) AI 기반 모델 학습 데이터의 정확도가 99%로 보이지만, 새로운 데이터를 입력하면 60%로 급락한다면 잘 학습된 모델이 아니다.(과적합)
2. 과적합(Overfitting) 및 과소적합(Underfitting) 방지
    1. 과적합 : 모델이 학습 데이터의 패턴을 지나치게 암기하면, 새로운 데이터에서 예측 성능이 낮아짐.
    2. 과소적합 : 모델이 충분한 패턴을 학습하지 못해 훈련 데이터에서도 낮은 성능을 보임.
3. 최적의 하이퍼파라미터 튜닝(Hyperparameter Tuning)
    1. 모델을 최적화하기 위해 하이퍼파라미터(예 : 학습률, 층의 개수, 정규화 파라미터 등)을 조정해야 함.
        1. 학습률(Learning rate)가 너무 크면 학습이 불안정하고, 너무 작으면 학습이 느리거나 최적점을 찾을 수 없음.
    2. 검증 데이터(validation set)을 활용하여 최적의 모델을 선택할 수 있음.
        1. 검증 데이터를 활요해 여러 하이퍼파라미터 설정을 테스트하고, 최적의 조합을 찾는 과정이 필수
4. 객관적인 모델 성능 평가
    1. A 모델과 B 모델이 있다. 둘의 학습 데이터 성능은 95%로 동일하지만 테스트 데이터에서 A 모델은 90%, B 모델은 75%의 정확도를 보인다면 A모델이 일반화 성능이 더 좋다.
5. 데이터셋 분할 전략(Training / Validation / Test Split)
    1. 훈련데이터 : 학습
        1. 모델이 가중치를 최적화하는 데 사용
    2. 검증데이터 : 하이퍼파라미터 조정
        1. 최적의 모델을 찾기 위한 성능 평가
    3. 테스트 데이터 : 최종 평가
        1. 학습에 전혀 사용되지 않은 데이터로 최종 평가
6. 일반화 성능을 높이는 방법
    1. 충분한 양의 데이터를 확보
        1. 데이터가 부족하면 모델이 편향될 가능성이 높음
    2. 데이터 증강(Data Augmentation) 활용
        1. 이미지, 텍스트 데이터 변형을 통해 다양한 학습 환경 제공
    3. 교차 검증 (Cross-Validation) 적용
        1. K-Fold 방식 등을 이용하여 더욱 객관적인 성능 평가 가능
            1. K-Fold : K-Fold 교차 검증은 **데이터를 여러 개의 그룹(K개)으로 나누어 반복적으로 훈련과 검증을 수행하는 방법 (특정 데이터에 치우치지 않고 더 객관적으로 평가가 진행될 수 있도록 도와주는 기법)**
                - 데이터를 K개의 그룹으로 나눔
                - 한개의 그룹을 검증용 데이터로 사용하고, 나머지를 학습용으로 사용
                - 이 과정을 K번 반복하여, 각 폴드가 한 번씩 검증용 데이터가 됨
                - 마지막에 K번의 검증 결과를 평균 내어 최종 성능을 평가
    4. 적절한 모델 선택
        1. 너무 복잡한 모델은 과적합 위험이 크고, 너무 단순하면 과소적합에 위험
7. 최종 요약
    1. 모델 신뢰성을 확보하려면 반드시 데이터셋을 학습데이터 / 검증데이터 / 테스트 데이터로 나눠야함.
    2. 과적합 방지 및 최적의 하이퍼파라미터 조정이 가능해짐
        1. 그래프를 그리면 보기 편하다.
    3. 실제 환경에서도 델이 높은 성능을 유지할 수 있도록 일반화 성능을 평가하는 것이 필수!!


### 오늘의 도전 과제와 해결 방법
- 도전 과제 1: 딥다이브를 진행하면서 머신러닝의 전반적인 내용을 다룰 수 있어서 좋았습니다. 

### 오늘의 회고
- 딥러닝 개념 정리를 한번 다시 해봐야할 것 같습니다.

### 참고 자료 및 링크
- [링크 제목](URL)
- [링크 제목](URL)
